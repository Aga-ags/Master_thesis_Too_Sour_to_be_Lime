---
title: "pH ANN"
author: "Agnieszka Kubica"
date: "`r Sys.Date()`"
output: html_document
---



```{r libraries}
library(dplyr)
library(sf)
library(tableone)
library(recipes)
set.seed(144)
```

# Load data 
```{r load_data}
df <- readRDS(file="../data/processed_data.Rda")
df
```
## Make sample weights
```{r}
df <- df |>
  mutate(sample_weight = ifelse(pH_origin == "site", 0.7, ifelse(pH_origin == "CaCl2", 1, 0.9)),
          sample_weight = ifelse(lime_imputed == TRUE, sample_weight-0.1, sample_weight))
```


## One code encoding for categorical 
```{r}
recipe_obj <- recipe(~ ., data = df) %>%
  step_dummy(all_nominal() &!any_of(c("pH_origin", "lime_imputed")), one_hot = TRUE) %>%
  prep()

one_hot_df <- bake(recipe_obj, new_data = NULL)
one_hot_df
```

## Split data
```{r}
df <- one_hot_df

#create ID column
df$id_row <- 1:nrow(df)

# subset non imputed data to create the test and validation sample from (around 3000 observations less from 14.000)
df_not_imputed <- df|>
  filter(pH_origin == "CaCl2" & lime_imputed == FALSE)

# find percentage to sample the imputed data to equal to 20 perc of entire sample
sample_20 <- 0.2 * nrow(df)
amount_of_non_imputed_equal_to_20_perc <- sample_20/ nrow(df_not_imputed)
amount_of_non_imputed_equal_to_20_perc

# testing and validation datasets 
test_and_validation_df <-  df_not_imputed %>% dplyr::sample_frac(amount_of_non_imputed_equal_to_20_perc)

validation <- test_and_validation_df %>% dplyr::sample_frac(0.50)
nrow(validation)
test <- dplyr::anti_join(test_and_validation_df, validation, by = 'id_row')
nrow(test)

# remaining df creates the train df: 
train  <- dplyr::anti_join(df, test_and_validation_df, by = 'id_row')
nrow(train)

# adjument the original df with which row belongs to which split:
df$split <- ifelse(df$id_row %in% train$id_row, "Train",
                   ifelse(df$id_row %in% test$id_row, "Test", "Validation"))
```



## Investigate the representatives of test sample:
```{r}
test_sf <- st_as_sf(test, coords = c("x", "y"), crs = 2056)  
train_sf <- st_as_sf(train, coords = c("x", "y"), crs = 2056)
df_sf <- st_as_sf(df, coords = c("x", "y"), crs = 2056)

plot(st_geometry(df_sf), col = 'grey', main = "Train vs Test spatial distribution")
plot(st_geometry(train_sf), col = 'blue', add = TRUE)
plot(st_geometry(test_sf), col = 'red', add = TRUE)
legend("bottomright", legend = c("All", "Train", "Test"), col = c("grey", "blue", "red"), pch = 1)
```

```{r}
columns <- df|>
  select(-"x", -"y", - "split", -"id_row")|>
  colnames()
CreateTableOne(vars =columns, strata = "split", data = df)
```



# Save prepared data


```{r}
x_train <- train|>
  select(!c("pH", "pH_origin", "x", "y", "id_row", "sample_weight", "lime", "lime_imputed"))|>
  as.matrix()
y_train <- train$pH

x_valid <- validation|>
  select(!c("pH", "pH_origin", "x", "y", "id_row", "sample_weight", "lime", "lime_imputed"))|>
  as.matrix()
y_valid  <- validation$pH
```

```{r}
write.csv(x_train,file='../data/x_train.csv', row.names=FALSE)
write.csv(y_train,file='../data/y_train.csv', row.names=FALSE)
write.csv(x_valid,file='../data/x_valid.csv', row.names=FALSE)
write.csv(y_valid,file='../data/y_valid.csv', row.names=FALSE)
```

## Save training weights
```{r}
sample_wight_df <- train|>
  select("sample_weight")

write.csv(sample_wight_df,file='../data/sample_weights.csv', row.names=FALSE)
```


